\documentclass[a4paper,10pt]{jarticle}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage[dvipdfmx]{graphicx}
\usepackage{here}
\usepackage{longtable}
\usepackage{url}
\usepackage{listings}
\usepackage{color}
\setlength{\textwidth}{165mm}
\setlength{\marginparwidth}{40mm}
\setlength{\textheight}{225mm}
\setlength{\topmargin}{-5mm}
\setlength{\oddsidemargin}{-3.5mm}
\begin{document}
\title{確率論まとめ}
\maketitle
\section{確率空間}
\subsection{標本空間と事象}
\subsubsection{導入}
はじめに言葉を定義する。
ある試行を行ったときの事象を\textcolor{red}{標本点}と呼ぶ。標本点全体を\textcolor{red}{標本空間}と呼ぶ。
ここで標本空間を$\Omega$で示す。
試行を行った時の発生する事象を$A$で表す。$A$は標本空間の部分集合であり、
$A=\Omega$の時$A$を\textcolor{red}{全事象}、$A$が標本点を持たないとき$A$は\textcolor{red}{空事象}と呼ばれる。なお空事象は$\emptyset$で表される。
事象$A$が起きない事象を\textcolor{red}{補事象}と呼び、$A^C$で表される。

さらに2つ以上の事象を考えてみる。2つの事象$A$と$B$において少なくとも一方が起きるという事象を$A$と$B$の\textcolor{red}{和事象}と呼ばれる。これは$A\cup B$で表される。
また$A$、$B$の両方が起こる事象について\textcolor{red}{積事象}と呼び、$A\cap B$で表される。
$A$、$B$が同時に起こりえないことを\textcolor{red}{排反}と呼ぶ。

実例を示してみよう。サイコロを1回振ったときに結果は1,2,3,4,5,6のいずれかである。このときの結果1つ1つが標本点である。
標本空間は
\begin{equation}
    \Omega = \{1,2,3,4,5,6\}\tag{1,1}
\end{equation}
サイコロを振った時に6以下の自然数が出るという事象は$\Omega$のため全事象、7以上の自然数が出るという事象は空事象となる。
サイコロを振った時に奇数が出る事象を$A$とすると、補事象$A^C$は偶数が出る事象となる。
サイコロを振った時に3以下が出る事象を$B$とすると、$A$と$B$の和事象は$\{1,2,3,5\}$,積事象は$\{1,3\}$となる。
サイコロを振った時に5が出る事象を$C$とすると、$A$と$C$は排反である。

\subsubsection{ド・モルガンの法則}
和事象と積事象の補集合に関する法則である。
具体的には次式で表される。
\begin{equation}
    (A\cup B)^C = A^C\cap B^C\tag{1,2}
\end{equation}
\begin{equation}
    (A\cap B)^C = A^C\cup B^C\tag{1,3}
\end{equation}
ここで導入のサイコロの例をもとに実例を挙げてみよう。$A$はサイコロを振った時に奇数が出る事象、$B$はサイコロを振った時に3以下が出る事象である。
\begin{equation}
    (A\cup B)^C = \{1,2,3,5\}^C=\{4,6\}\tag{1,4}
\end{equation}
\begin{equation}
    A^C\cap B^C = \{1,3,5\}^C\cap\{1,2,3\}^C=\{2,4,6\}\cap\{4,5,6\}=\{4,6\}\tag{1,5}
\end{equation}
\begin{equation}
    (A\cap B)^C = \{1,3\}^C = \{2,4,5,6\}\tag{1,6}
\end{equation}
\begin{equation}
    A^C\cup B^C = \{1,3,5\}^C\cap\{1,2,3\}^C=\{2,4,6\}\cap\{4,5,6\} = \{2,4,5,6\}\tag{1,7}
\end{equation}
\subsubsection{結合法則及び分配法則}
確率の事象にも結合法則及び分配法則が適応可能。具体的には次式で表される。
\begin{equation}
    (A\cup B)\cup C = A\cup B \cup C\tag{1,8}
\end{equation}
\begin{equation}
    (A\cap B)\cap C = A\cap B\cap C \tag{1,9}
\end{equation}
\begin{equation}
    (A\cup B)\cap C = (A\cap C)\cup(B\cap C)\tag{1,10}
\end{equation}
\begin{equation}
    (A\cap B)\cup C = (A\cup C)\cap(B\cup C)\tag{1,11}
\end{equation}
\subsection{確率の定義}
確率とは\textcolor{red}{事象の起きやすさを表す量}である。事象$A$が起きる確率を$P(A)$と表す。
具体的には以下に示す\textcolor{red}{確率の公理}を満たす写像$P(A)$を確立と呼ぶ。
\begin{itemize}
    \item 事象Aに対して$P(A)$は実数である。そして$0\leq P(A)\leq 1$
    \item $P(\Omega)=1$
    \item 互いに排反な事象$A_1,\cdots,A_n$に対して、$P(A_1\cup\cdots\cup A_N)=P(A_1)+\cdots+P(A_n)$
\end{itemize}
\subsection{確率の性質}
確率の公理より簡単に導くことができる性質を以下に示す。
\begin{equation}
    P(\emptyset)=0\tag{1,12}
\end{equation}
\begin{equation}
    P(A^C)= 1-P(A)\tag{1,13}
\end{equation}
\begin{equation}
    A\subset B => P(A) \leq P(B)\tag{1,14}
\end{equation}
\subsubsection{加法定理}
さらに確率の公理より次の等式が成立する。
\begin{equation}
    P(A\cup B) = P(A\cap B^C) +P(A\cap B )+ P(A^C\cap B)\tag{1,15}
\end{equation}
\begin{equation}
    P(A) = P(A\cap B^C) +P(A\cap B)\tag{1,16}
\end{equation}
\begin{equation}
    P(A) = P(A^C\cap B) + P(A\cap B)\tag{1,17}
\end{equation}
これら3式を足すことで\textcolor{red}{加法定理}が得られる。
\begin{equation}
    P(A\cup B )= P(A)+P(B)-P(A\cap B)\tag{1,18}
\end{equation}
\subsection{条件付確率}
2つの事象$A$と$B$に対して、事象$A$が起きたという条件の下で事象$B$が起きるといった確率を\textcolor{red}{条件付確率}と呼び$P(B|A)$と表す。
条件付確率は次式で求めることができる。
\begin{equation}
    P(B|A)=\frac{P(A\cap B)}{P(A)}\tag{1,19}
\end{equation}
また次式を変形すると
\begin{equation}
    P(A\cap B)=P(A)P(B|A)\tag{1,20}
\end{equation}
なおこの式を\textcolor{red}{乗法定理}と呼ぶ。

具体例を考えてみる。
袋Xが1つと袋Yが2つ存在し、袋Xには赤玉3個白玉1個、袋Yには赤玉2個白玉1個あるとする。
袋を1つ選びその中から1つ球をとるということを考える。袋Xを引いたときに白玉を引く確率を考える。
袋Xを引く事象を$A$、白玉を引く事象を$B$とする。$P(A)=\frac{1}{3}$であり、$P(A\cap B)=\frac{1}{12}$
よって条件付確率$P(B|A)=\frac{1}{4}$である。

また袋Yを引く事象を$C$、赤玉を引く事象を$D$とすると、$P(C)=\frac{2}{3}$、$P(D|C)=\frac{1}{2}$のため、乗法定理より$P(C\cap D)=\frac{1}{3}$となる。
もしこの具体例がわからない場合は図示して考えてみるとよい。

\subsection{独立性}
2つの事象$A$と$B$に対して、$P(B|A)=P(B)$となるとき、事象$A$と事象$B$は\textcolor{red}{独立}という。
独立である条件は$A$が$B$に依存しないことである。このとき乗法定理は次のように変形できる。
\begin{equation}
    P(A\cap B) = P(A)P(B)\tag{1,21}
\end{equation}

実例としてサイコロを2回振った時の出目の組み合わせを考えてみる。
1回目に振り奇数が出る事象を$A$、2回目に振り奇数が出る事象を$B$とすると、$A$と$B$はお互い依存していない。
よって$P(A\cap B)= P(A)P(B)=\frac{1}{2}\cdot\frac{1}{2}=\frac{1}{4}$となる。
\subsection{ベイズの定理}
事象$A$が事象$B_1,\cdots,B_k$の事象が発生したときのみに起こりうるということを考える。そして$B_1,\cdots,B_k$以外の事象が発生したときに$A$は起こらないこととする。
つまり事象$B_i$が発生し、事象$A$が起こるような条件を考える。
このとき事象Aが起きたときにそれが$B_i$という事象であったという条件付確率を求める。
この時求める確率は$P(B_i|A)$となる。(1,19)式より、
\begin{equation}
    P(B_i|A) = \frac{P(B_i\cap A)}{P(A)}\tag{1,22}
\end{equation}
ここで$A$というのは条件$B,\cdots,B_k$が起こった上で発生するため、
\begin{equation}
    P(A) =\sum^k_{j=1}P(A\cap B_j)=\sum^k_{j=1}P(B_j)P(A|B_j)\tag{1,23}
\end{equation}
よって次式が成立する。
\begin{equation}
    P(B_i|A) = \frac{P(B_i\cap A)}{\sum^k_{j=1}P(B_j)P(A|B_j)}\tag{1,23}
\end{equation}
なおこの式を\textcolor{red}{ベイズの定理}と呼ぶ。

やはり式だけ見てもわかりずらいため実例を出してみる。
袋B$_1$に赤玉3つ白玉1つ、袋B$_2$に赤玉2つ白玉2つ、袋B$_3$に赤玉3つ白玉2つあるとする。
この時袋B$_i$を選ぶ事象を$B_i$とし、白玉を選ぶ事象を$A$とする。
ここで白玉を引いたときにそれが袋B$_2$から引いたものである確率をベイズの定理を用いて計算する。
まず$B_i$だが3種類の袋を偏りなく選ぶため確率は$\frac{1}{3}$。ここで$P(A|B_1)=\frac{1}{3}$,$P(A|B_2)=\frac{1}{2}$,$P(A|B_3)=\frac{2}{5}$
よってベイズの定理より、
\begin{equation}
    P(B_2|A)=\frac{\frac{1}{3}\cdot\frac{1}{2}}{\frac{1}{3}\cdot\frac{1}{4}+\frac{1}{3}\cdot\frac{1}{2}+\frac{1}{3}\cdot\frac{2}{5}}=\frac{10}{23}\tag{1,24}
\end{equation}
\section{確率変数と確率分布}
\subsection{確率変数と確率分布}
\subsubsection{確率変数}
ある変数の値をとる確率が存在する変数を\textcolor{red}{確率変数}と呼ぶ。例えばサイコロならば1から6までの整数値をとるため1,2,3,4,5,6が確率変数となり、$P(X)=\frac{1}{6}$となる。
\subsubsection{離散型と連続型}
確率変数$X$が可算個の離散値の場合、確率変数$X$は\textcolor{red}{離散型}となる。また確率変数$X$が連続値をとる場合は\textcolor{red}{連続型}となる。以降\textcolor{red}{離散型か連続型によって使用できる式が異なる}ためしっかりと判別しよう。
\subsubsection{確率関数}
まず、\textcolor{blue}{離散型}確率変数の確率を表現する関数として次の式を考える。なお$X$は確率変数を、$x$は取りうる値を示している。今後の説明のため$x=x_1,x_2\cdots x_i\cdot$とする。
\begin{equation}
    f(x)=P(X=x)\tag{2,1}
\end{equation}
この$f(x)$を\textcolor{red}{確率関数}と呼ぶ。
ここで確率関数は次の2つの性質を当然満たす。
\begin{equation}
    f(x_i)>0\tag{2,2}
\end{equation}
\begin{equation}
    \sum^\infty_{i=1}f(x_i)= 1\tag{2,3}
\end{equation}
\subsubsection{確率密度関数}
次に\textcolor{blue}{連続型}の場合の確率関数のようなものを考える。
連続型確率変数$X$が区間$(a,b]$にあるとする。この時の確率を
\begin{equation}
    P(a<X\leq b)= \int_{a}^{b} f(t)dt\tag{2,4}
\end{equation}
で考える。この確率関数のようなものは次の2つの性質を当然満たす。
\begin{equation}
    f(x)\geq 0\tag{2,5}
\end{equation}
\begin{equation}
    \int_{-\infty}^{\infty} f(x)dx= 1\tag{2,6}
\end{equation}
この関数$f(x)$を\textcolor{red}{確率密度関数}と呼ぶ。
\subsubsection{分布関数}
確率関数および確率密度関数ではある1点やある区間での確率であった。しかし場合によっては確率が積もっていく様子を捉えたいこともある。
よって確率が積もっていく様子を捉える量として\textcolor{red}{分布関数}というものを用意する。分布関数は\textcolor{red}{大文字のFで表す。}分布関数は次で示す。
\begin{equation}
    F(X)=P(X\leq x)\tag{2,7}
\end{equation}
さらに分布関数は次の性質を持っている
\begin{itemize}
    \item $F(a)\leq F(b) \ \ \ (a<b)$
    \item $0\leq F(x) \leq 1$
    \item $F(x)$は右連続
\end{itemize}
さてここまで書いたことを考えると当然だが分布関数が決まると確率(密度)関数は同時に決定する。同様に確率(密度)関数が決定すると分布関数が決定する。
ここで\textcolor{blue}{離散型}の確率関数と分布関数の関係をまとめる。
\begin{equation}
    F(x) = P(X\leq x) =\sum_{x_i\leq x}f(x_i)\tag{2,8}
\end{equation}
次に\textcolor{blue}{連続型}の確率密度関数と分布関数の関係をまとめる。
\begin{equation}
    F(x) = P(X\leq x) = \int_{-\infty}^x f(t)dt\tag{2,9}
\end{equation}
なお密度関数や分布関数による確率的挙動を\textcolor{red}{確率分布}と呼んでいるが、確率分布については3節にて触れる。
\subsection{期待値と平均と分散}
\subsubsection{平均そして期待値}
\textcolor{blue}{離散型}の平均$\mu$について以下のように定義する。
\begin{equation}
    \mu = \sum_{i= 1,2,\cdots} x_if(x_i)\tag{2,10}
\end{equation}

実例を挙げてみよう。サイコロの出目の平均を計算すると3.5となる。

\textcolor{blue}{連続型}の平均$\mu$について以下のように定義する。なお確率変数$X$が取りうる領域を$\mathcal{X} $とする。
\begin{equation}
    \mu = \int_\mathcal{X}xf(x)dx\tag{2,11}
\end{equation}
そしてこれら平均を総じて確率変数$X$の\textcolor{red}{期待値}という。期待値は$E[x]$で表される。
なお$E[X]$は線形性を持っており場合によっては計算が楽である。
\subsubsection{分散}
確率変数のばらつきを捉えるものに\textcolor{red}{分散}がある。これは確率変数$X$の平均$\mu$からの離れ具合を2乗に基づいて平均的に測るものである。分散$sigma^2=V(x)$は次式で定義する。
\begin{equation}
    \sigma^2=V[x]=E[(X-\mu)^2]\tag{2,12}
\end{equation}
これは\textcolor{blue}{離散型},\textcolor{blue}{連続型}どちらでも使うことができる。ただし期待値はそれぞれ対応する式で用いること。

\subsubsection{標準偏差}
分散はばらつきの尺度として優秀な一方で2乗しているため元の確率変数と単位が異なる。よって単位を合わせるために分散の平方根を\textcolor{red}{標準偏差}とする。
\subsubsection{k次モーメント}
一般的に$E[X^k]$を\textcolor{red}{k次モーメント}という。そして$E[(X-\mu)^k]$を\textcolor{red}{k次の中心モーメント}という。そして
今まで出たものをまとめると、平均は1次のモーメント、分散は2次の中心モーメントである。

ここで期待値が線形であり、$E[X]=\mu$を利用することで平均と分散に関して次の関係性を導くことができる。
\begin{eqnarray*}
    \sigma^2 &=& E[(X-\mu)^2]\\
    &=& E[X^2-2\mu X +\mu-2]\\
    &=& E[X^2]-2\mu E[X]+E[\mu^2]\\
    &=& E[X^2]-\mu^2
\end{eqnarray*}
\subsubsection{標準化}
世の中の無数の確率変数が同じ平均と標準偏差を持つように確率変数を変換することを\textcolor{red}{標準化}と呼ぶ。具体的に以下のように変換する。なお$Z$は確率変数である。
\begin{equation}
    Z=\frac{X-\mu}{\sigma}\tag{2,13}
\end{equation}
このとき平均$E[Z]$は0、分散$V[Z]$は1になる。

逆に標準化されている確率変数$Z$に対して、$X=\mu+\sigma Z$と変換すると、$E[X]=\mu$と$V[x]=\sigma^2$が簡単に得られる。

\subsection{多次元確率変数と同時確率分布と周辺確率分布}
\subsubsection{多次元確率変数}
まず1次元の確率変数$X_1,\cdots,X_k$をまとめた確率変数$X=(X_1,\cdots,X_k)$を\textcolor{red}{多次元確率変数}という。これはベクトルである。
\subsubsection{同時確率分布}
例えば袋の中に赤、青、黄の3色のボールが入ってることを考える。そしてそのボールには1から4までの数字が書かれている。
この時それぞれのボールの確率を求めるにはボールの色という確率変数とボールの数字という確率変数の2種類を考慮しなければならない。

このようにいくつかの確率変数を同時に扱うときの確率分布を\textcolor{red}{同時確率分布}という。

\textcolor{blue}{離散型}の場合、次式で示される。
\begin{equation}
    f(x_i,y_j\cdots)=P(X=x_i,Y=y_j\cdots)\tag{2,14}
\end{equation}
\textcolor{blue}{連続型}の場合、次式で示される。
\begin{equation}
    f(a<X\leq b,c<Y\leq d\cdots)=\int_a^b\int_c^d\cdot f(x,y,\cdots) dxdy\cdots\tag{2,15}
\end{equation}
\subsubsection{周辺確率分布}
\textcolor{red}{周辺確率}とは、ただ1つだけの事象が起こる確率である。
つまり1つの変数を固定し、もう1つの変数のパターンをすべて足せばいい。
\textcolor{blue}{離散型}の場合、次式を例とする。
\begin{equation}
    P(X_1=x_1)=\sum_{x_2}\sum_{X_3}\cdots P(X_1 = x_1,X_2 = x_2, X_3 = x_3\cdots)\tag{2,16}
\end{equation}
要は1つの確率変数を固定して後ひたすら足しているだけなのだ。
\textcolor{blue}{連続型}の場合、次式を例とする。
\begin{equation}
    P(X_1\leq x_1,-\infty < X_2 < \infty \cdots) = \int_{-\infty}^x\int_{-\infty}^\infty\cdots f(x_1,c_2,\cdots)dx_1dx_2\cdots\tag{2,17}
\end{equation}
\subsection{共分散}
2つの確率変数$X$と$Y$の関係を表す量として\textcolor{red}{共分散}を次式で定義する。
\begin{equation}
    \sigma_{xy}=Cov[X,Y]=E[(X-\mu_x)(Y-\mu_y)] \tag{2,18}
\end{equation}
また共分散の代わりに\textcolor{red}{相関係数}に着目することもある。相関係数は次式で定義される。
\begin{equation}
    \rho_{xy} = Corr[X,Y] = \frac{Cov[X,Y]}{\sqrt{V[X]V[Y]}}\tag{2,19}
\end{equation}
\subsection{確率変数の和の平均と分散}
確率変数の和$X+Y$における平均と分散は次式で表すことができる。
\begin{itemize}
    \item 和：$E[X+Y] = E[X]+E[Y]$
    \item 分散: $V[X+Y] = V[X]+V[Y] + 2Cov[X,Y]$
\end{itemize}
なお分散については以下に導出を記載しておく。
\begin{eqnarray*}
    V[X+Y] &=& E[\{(X+Y)-(\mu_x+\mu_Y)\}^2]\\
            &=& E[\{(X-\mu_x)+(Y-\mu_Y)\}^2]\\
            &=& E[(X-\mu_x)^2]+E[(Y-\mu_y)^2]+2E[(X-\mu_x)(Y-\mu_y)]\\
            &=& V[X]+V[Y]+2Cov[X,Y]
\end{eqnarray*}
\subsection{確率不等式}
\subsubsection{チェビシェフの不等式}
\textcolor{red}{チェビシェフの不等式}を紹介する。
確率変数$X$における平均と分散を用いる。このとき任意の$\varepsilon >0$に対して、次が成り立つ。
\begin{equation}
    P[(|X-\mu\geq\varepsilon)]\leq \frac{\sigma^2}{\varepsilon^2}\tag{2,20}
\end{equation}
この不等式は、特定の値以下もしくは以上の累積分布関数の最大値を求めることができる。
\subsubsection{コーシー・シュバルツの不等式}
次に\textcolor{red}{コーシー・シュバルツの不等式}を紹介する。
コーシー・シュバルツの不等式は確率変数$X$と$Y$の分散と共分散との間に次の不等式が成立するというものである。
\begin{equation}
    Cov[X,Y] ^2,\leq V[X]V[Y]\tag{2,21}
\end{equation}
\subsection{条件付密度関数}
確率変数$X=x$、$Y=y$の時の\textcolor{red}{条件付密度関数}$f_{Y|X}(y|x)$を次式で定義する。
\begin{equation}
    f_{Y|X}(y|x)=\frac{f(x,y)}{f_X(x)}\tag{2,22}
\end{equation}

\end{document}